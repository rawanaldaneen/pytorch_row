{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMuc8c81efMNBVPfNTqqgUh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f256f4164737407c8e37db8408b221e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87bc3bdfcaed44b48a31e4c52e292c13",
              "IPY_MODEL_dc335393f41943dca27ca7b68267a01f",
              "IPY_MODEL_887e5560be4946e3926c22e928b90543"
            ],
            "layout": "IPY_MODEL_a65a7aaa872c435ab6570b0e5bdcbf12"
          }
        },
        "87bc3bdfcaed44b48a31e4c52e292c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1e1f1b55584737b4199aaa80f3c97b",
            "placeholder": "​",
            "style": "IPY_MODEL_4603ea7c28d84841a5c8ec8c582f4416",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "dc335393f41943dca27ca7b68267a01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef0f860f3f14c60ad961b327eefecac",
            "max": 445,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dce4a2241b9949e4b58209915cb62e20",
            "value": 445
          }
        },
        "887e5560be4946e3926c22e928b90543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e702e0e5bfb44b129dd414cf3e40c342",
            "placeholder": "​",
            "style": "IPY_MODEL_40e070dac8b347e48d3c34940e0363a7",
            "value": " 445/445 [00:00&lt;00:00, 37.3kB/s]"
          }
        },
        "a65a7aaa872c435ab6570b0e5bdcbf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1e1f1b55584737b4199aaa80f3c97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4603ea7c28d84841a5c8ec8c582f4416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef0f860f3f14c60ad961b327eefecac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce4a2241b9949e4b58209915cb62e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e702e0e5bfb44b129dd414cf3e40c342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e070dac8b347e48d3c34940e0363a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e144a2eb640486aacd885f3f32e9a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e41835cea5e6479eba5b1acda7f25124",
              "IPY_MODEL_624a2a99b3ca4e85acad7bc02cbd7d72",
              "IPY_MODEL_b318a017e61e4e6083517697635b1317"
            ],
            "layout": "IPY_MODEL_19dfc4b2ad834556ac090c75c7a1b1c5"
          }
        },
        "e41835cea5e6479eba5b1acda7f25124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c25183ead9e4f4eb54c6e52a95b6664",
            "placeholder": "​",
            "style": "IPY_MODEL_5c60b064bf7f4e58a0c284f4f160a5bd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "624a2a99b3ca4e85acad7bc02cbd7d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b57009c2c7484831a5c4a2472eff24be",
            "max": 527,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab4c80695f1f4b9d9989c249fbe420f5",
            "value": 527
          }
        },
        "b318a017e61e4e6083517697635b1317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_093ab928c20c49c6a3d5183df54bf157",
            "placeholder": "​",
            "style": "IPY_MODEL_5f198450f0d94d9fb12f76fbb49f6465",
            "value": " 527/527 [00:00&lt;00:00, 72.5kB/s]"
          }
        },
        "19dfc4b2ad834556ac090c75c7a1b1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c25183ead9e4f4eb54c6e52a95b6664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c60b064bf7f4e58a0c284f4f160a5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b57009c2c7484831a5c4a2472eff24be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4c80695f1f4b9d9989c249fbe420f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "093ab928c20c49c6a3d5183df54bf157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f198450f0d94d9fb12f76fbb49f6465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ded68c66ba46478756b95369e20a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7359377a9afa46c8bceaf8b9788caed3",
              "IPY_MODEL_676e55ac54b649d197a8e19201d112d6",
              "IPY_MODEL_f7dcac2a263044fe8e9f9f5afda78b31"
            ],
            "layout": "IPY_MODEL_63f2b2c567d444bf8f53f5d5746f78fd"
          }
        },
        "7359377a9afa46c8bceaf8b9788caed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68aabf7712024d6599ba2de5c62d63a2",
            "placeholder": "​",
            "style": "IPY_MODEL_f4ca31af12374ec5a9e06a5f941fcb98",
            "value": "vocab.txt: "
          }
        },
        "676e55ac54b649d197a8e19201d112d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62ea3e0366f424daa0dfa107c806695",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80db2d8fce7a4568a8098f72f6754be5",
            "value": 1
          }
        },
        "f7dcac2a263044fe8e9f9f5afda78b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3150d18ca8324654aa1f8c49fce5664c",
            "placeholder": "​",
            "style": "IPY_MODEL_a7d3384c40a549e2a8ca83ff3726ad9c",
            "value": " 232k/? [00:00&lt;00:00, 5.23MB/s]"
          }
        },
        "63f2b2c567d444bf8f53f5d5746f78fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68aabf7712024d6599ba2de5c62d63a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ca31af12374ec5a9e06a5f941fcb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b62ea3e0366f424daa0dfa107c806695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "80db2d8fce7a4568a8098f72f6754be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3150d18ca8324654aa1f8c49fce5664c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d3384c40a549e2a8ca83ff3726ad9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ccfea73f5ff4a699cdda65599c9c9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_356e4d9bd4144410a5d6c416c6f40237",
              "IPY_MODEL_7b71db86750d4f0e8c6d3d842536c490",
              "IPY_MODEL_d2c59584fc8d4caba0a89349a6d1b8ef"
            ],
            "layout": "IPY_MODEL_723247a0ef3f4ee393e850620e0aec29"
          }
        },
        "356e4d9bd4144410a5d6c416c6f40237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387d253b883c42ccae422966f63854a4",
            "placeholder": "​",
            "style": "IPY_MODEL_bebaafe7896048f3a2df21ebf61d5e9e",
            "value": "tokenizer.json: "
          }
        },
        "7b71db86750d4f0e8c6d3d842536c490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda6b783a148458786ef870f48808e08",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55f9a9260bbe444885ce83e54df8ff4e",
            "value": 1
          }
        },
        "d2c59584fc8d4caba0a89349a6d1b8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd87bc0491f54757be47623346ce83af",
            "placeholder": "​",
            "style": "IPY_MODEL_489ba9faf659460e863c5aa851de9280",
            "value": " 711k/? [00:00&lt;00:00, 24.7MB/s]"
          }
        },
        "723247a0ef3f4ee393e850620e0aec29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387d253b883c42ccae422966f63854a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bebaafe7896048f3a2df21ebf61d5e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bda6b783a148458786ef870f48808e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "55f9a9260bbe444885ce83e54df8ff4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd87bc0491f54757be47623346ce83af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489ba9faf659460e863c5aa851de9280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eacd6eee99a04443af488cd942ab7d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ffe339e625249e8925ef664396c77ab",
              "IPY_MODEL_9859b5c83bc74a79b4c4d1938ef959c3",
              "IPY_MODEL_8223bcfb283b44268ade2ec82a7d9a58"
            ],
            "layout": "IPY_MODEL_0df94818d8db464c92f5f5d79f1e06c9"
          }
        },
        "1ffe339e625249e8925ef664396c77ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425cb0406405455cbe0ff8a6c6ef034a",
            "placeholder": "​",
            "style": "IPY_MODEL_c9735d0cd4f9464ebb281a1a0c43d665",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9859b5c83bc74a79b4c4d1938ef959c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d54caeed31e412c912eadcdbb7c1ba9",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab03d2ec99044887a11052182f349dce",
            "value": 125
          }
        },
        "8223bcfb283b44268ade2ec82a7d9a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5bf144991154fad9ce973ee19ea94ee",
            "placeholder": "​",
            "style": "IPY_MODEL_2e50561725804ee580d5ca26783f7d16",
            "value": " 125/125 [00:00&lt;00:00, 18.1kB/s]"
          }
        },
        "0df94818d8db464c92f5f5d79f1e06c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425cb0406405455cbe0ff8a6c6ef034a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9735d0cd4f9464ebb281a1a0c43d665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d54caeed31e412c912eadcdbb7c1ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab03d2ec99044887a11052182f349dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5bf144991154fad9ce973ee19ea94ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e50561725804ee580d5ca26783f7d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00ff03d3720741ddadc15a705b58bf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceb55d8d05b84d25914ef058ada4f318",
              "IPY_MODEL_eed22b81a1344690a3b6d6640ec5072e",
              "IPY_MODEL_1d30cd92520e4514ba355ad887c3217f"
            ],
            "layout": "IPY_MODEL_175f032bac474dba926409204e97b716"
          }
        },
        "ceb55d8d05b84d25914ef058ada4f318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7666c4194f14dec973e43c035fb32fc",
            "placeholder": "​",
            "style": "IPY_MODEL_c88c9b3ad4c44d8ba6a32052ec0f0cc8",
            "value": "config.json: "
          }
        },
        "eed22b81a1344690a3b6d6640ec5072e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea629c2cf224dcc9e246a64132091ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f69064fe388a41889e23e9f308345d59",
            "value": 1
          }
        },
        "1d30cd92520e4514ba355ad887c3217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7f83957aa04c4c9a5429284e60e0b8",
            "placeholder": "​",
            "style": "IPY_MODEL_35ce6717f4e34df09d92425073f36c8d",
            "value": " 4.60k/? [00:00&lt;00:00, 511kB/s]"
          }
        },
        "175f032bac474dba926409204e97b716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7666c4194f14dec973e43c035fb32fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88c9b3ad4c44d8ba6a32052ec0f0cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fea629c2cf224dcc9e246a64132091ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f69064fe388a41889e23e9f308345d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a7f83957aa04c4c9a5429284e60e0b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ce6717f4e34df09d92425073f36c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "546d1eeeed9b465abb30d56c5ede788b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_724239f67fe64995996e52c744e12fb5",
              "IPY_MODEL_391d737493d14e5a8ac9696a303d9ca6",
              "IPY_MODEL_63236fdb7f934e4ebbc918da60265cd4"
            ],
            "layout": "IPY_MODEL_75fceed9a16b4aaa812d171acbceb3b9"
          }
        },
        "724239f67fe64995996e52c744e12fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40482d2647104dcc8bf5b5cf37acb2bf",
            "placeholder": "​",
            "style": "IPY_MODEL_992d2996ebe0432fb3449dd540b32c1e",
            "value": "model.safetensors: 100%"
          }
        },
        "391d737493d14e5a8ac9696a303d9ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ceae08e1a754b9ea03c713957aa2875",
            "max": 1879014680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbcc9a9b00bc41a1847cf03b01d7ff41",
            "value": 1879014680
          }
        },
        "63236fdb7f934e4ebbc918da60265cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81cd1c01ed8a44118141e4b8df6fb53a",
            "placeholder": "​",
            "style": "IPY_MODEL_7de6403b91a4488abbb9235de46db08d",
            "value": " 1.88G/1.88G [00:09&lt;00:00, 302MB/s]"
          }
        },
        "75fceed9a16b4aaa812d171acbceb3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40482d2647104dcc8bf5b5cf37acb2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992d2996ebe0432fb3449dd540b32c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ceae08e1a754b9ea03c713957aa2875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcc9a9b00bc41a1847cf03b01d7ff41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81cd1c01ed8a44118141e4b8df6fb53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de6403b91a4488abbb9235de46db08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rawanaldaneen/pytorch_row/blob/main/Landscape_Captioning_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess, torch\n",
        "\n",
        "# Unhide GPU if it was disabled earlier (you had this in captioning code)\n",
        "os.environ.pop(\"CUDA_VISIBLE_DEVICES\", None)\n",
        "\n",
        "# OS-level check\n",
        "print(\"=== nvidia-smi ===\")\n",
        "try:\n",
        "    print(subprocess.check_output([\"nvidia-smi\"]).decode())\n",
        "except Exception as e:\n",
        "    print(\"NO GPU visible to OS:\", e)\n",
        "\n",
        "# PyTorch check\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torch.version.cuda:\", torch.version.cuda)\n",
        "print(\"cuda.is_available():\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"device:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "id": "mMx_K_HKgJG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b92be4-d6a7-48a5-9f73-9dc518e34655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== nvidia-smi ===\n",
            "Thu Oct 16 15:07:14 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "torch: 2.8.0+cu126\n",
            "torch.version.cuda: 12.6\n",
            "cuda.is_available(): True\n",
            "device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P-TBFsYrRtN_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3100e572"
      },
      "source": [
        "# Task\n",
        "Externalize the configuration settings (TRIGGER_TOKEN, DOMAIN_KEYWORDS, etc.) from the script `iraqi_marshes_captioner.py` into a `config.yaml` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ce116b9"
      },
      "source": [
        "## Install a configuration library\n",
        "\n",
        "### Subtask:\n",
        "Install a library like `PyYAML` to handle reading from a YAML file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deb1392e"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing the PyYAML library. I will use the `!pip install` command in a code block to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16859d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b537aa52-2f1b-468a-b5d9-2e432438c8ac"
      },
      "source": [
        "!pip install PyYAML"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (6.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6bf811"
      },
      "source": [
        "## Create a configuration file\n",
        "\n",
        "### Subtask:\n",
        "Generate a new code cell to create a `config.yaml` file in the `/content` directory with the current configuration settings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f99dabd"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to create a `config.yaml` file with the specified content. This requires using Python's file handling to write the YAML formatted data to the file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a641db9f",
        "outputId": "3424e614-2ff3-4718-b7cb-695cdf93677d"
      },
      "source": [
        "import yaml\n",
        "\n",
        "config_data = {\n",
        "    \"IMAGE_FOLDER\": \"/content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo\",\n",
        "\n",
        "    \"OUTPUT_CSV\": \"/content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\",\n",
        "    \"TRIGGER_TOKEN\": None,\n",
        "    \"N_CANDIDATES\": 3,\n",
        "    \"SKIP_IF_TXT_EXISTS\": True,\n",
        "    \"BATCH_SIZE\": 8,\n",
        "    \"DOMAIN_KEYWORDS\": [\"mashoof\", \"mashoof boat\", \"reeds\", \"reed\", \"marsh\", \"marshes\", \"Mesopotamian Marshes\", \"Iraqi marshes\", \"water buffalo\"],\n",
        "    \"BANNED_TERMS\": [\"skier\", \"ski\", \"snow\", \"snowy\", \"mountain\", \"ocean\", \"beach resort\"]\n",
        "}\n",
        "\n",
        "config_file_path = \"/content/config.yaml\"\n",
        "\n",
        "with open(config_file_path, 'w') as f:\n",
        "    yaml.dump(config_data, f, default_flow_style=False)\n",
        "\n",
        "print(f\"Updated {config_file_path} with new IMAGE_FOLDER.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated /content/config.yaml with new IMAGE_FOLDER.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb08f2ce"
      },
      "source": [
        "## Modify the script to read configuration\n",
        "\n",
        "### Subtask:\n",
        "Update the Python script (`iraqi_marshes_captioner.py`) to read the configuration from the `config.yaml` file instead of having the settings hardcoded.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a869cc75"
      },
      "source": [
        "**Reasoning**:\n",
        "Update the python script to read configuration from the yaml file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886,
          "referenced_widgets": [
            "f256f4164737407c8e37db8408b221e2",
            "87bc3bdfcaed44b48a31e4c52e292c13",
            "dc335393f41943dca27ca7b68267a01f",
            "887e5560be4946e3926c22e928b90543",
            "a65a7aaa872c435ab6570b0e5bdcbf12",
            "be1e1f1b55584737b4199aaa80f3c97b",
            "4603ea7c28d84841a5c8ec8c582f4416",
            "8ef0f860f3f14c60ad961b327eefecac",
            "dce4a2241b9949e4b58209915cb62e20",
            "e702e0e5bfb44b129dd414cf3e40c342",
            "40e070dac8b347e48d3c34940e0363a7",
            "4e144a2eb640486aacd885f3f32e9a60",
            "e41835cea5e6479eba5b1acda7f25124",
            "624a2a99b3ca4e85acad7bc02cbd7d72",
            "b318a017e61e4e6083517697635b1317",
            "19dfc4b2ad834556ac090c75c7a1b1c5",
            "4c25183ead9e4f4eb54c6e52a95b6664",
            "5c60b064bf7f4e58a0c284f4f160a5bd",
            "b57009c2c7484831a5c4a2472eff24be",
            "ab4c80695f1f4b9d9989c249fbe420f5",
            "093ab928c20c49c6a3d5183df54bf157",
            "5f198450f0d94d9fb12f76fbb49f6465",
            "19ded68c66ba46478756b95369e20a4e",
            "7359377a9afa46c8bceaf8b9788caed3",
            "676e55ac54b649d197a8e19201d112d6",
            "f7dcac2a263044fe8e9f9f5afda78b31",
            "63f2b2c567d444bf8f53f5d5746f78fd",
            "68aabf7712024d6599ba2de5c62d63a2",
            "f4ca31af12374ec5a9e06a5f941fcb98",
            "b62ea3e0366f424daa0dfa107c806695",
            "80db2d8fce7a4568a8098f72f6754be5",
            "3150d18ca8324654aa1f8c49fce5664c",
            "a7d3384c40a549e2a8ca83ff3726ad9c",
            "2ccfea73f5ff4a699cdda65599c9c9a6",
            "356e4d9bd4144410a5d6c416c6f40237",
            "7b71db86750d4f0e8c6d3d842536c490",
            "d2c59584fc8d4caba0a89349a6d1b8ef",
            "723247a0ef3f4ee393e850620e0aec29",
            "387d253b883c42ccae422966f63854a4",
            "bebaafe7896048f3a2df21ebf61d5e9e",
            "bda6b783a148458786ef870f48808e08",
            "55f9a9260bbe444885ce83e54df8ff4e",
            "dd87bc0491f54757be47623346ce83af",
            "489ba9faf659460e863c5aa851de9280",
            "eacd6eee99a04443af488cd942ab7d9a",
            "1ffe339e625249e8925ef664396c77ab",
            "9859b5c83bc74a79b4c4d1938ef959c3",
            "8223bcfb283b44268ade2ec82a7d9a58",
            "0df94818d8db464c92f5f5d79f1e06c9",
            "425cb0406405455cbe0ff8a6c6ef034a",
            "c9735d0cd4f9464ebb281a1a0c43d665",
            "6d54caeed31e412c912eadcdbb7c1ba9",
            "ab03d2ec99044887a11052182f349dce",
            "b5bf144991154fad9ce973ee19ea94ee",
            "2e50561725804ee580d5ca26783f7d16",
            "00ff03d3720741ddadc15a705b58bf2a",
            "ceb55d8d05b84d25914ef058ada4f318",
            "eed22b81a1344690a3b6d6640ec5072e",
            "1d30cd92520e4514ba355ad887c3217f",
            "175f032bac474dba926409204e97b716",
            "d7666c4194f14dec973e43c035fb32fc",
            "c88c9b3ad4c44d8ba6a32052ec0f0cc8",
            "fea629c2cf224dcc9e246a64132091ac",
            "f69064fe388a41889e23e9f308345d59",
            "5a7f83957aa04c4c9a5429284e60e0b8",
            "35ce6717f4e34df09d92425073f36c8d",
            "546d1eeeed9b465abb30d56c5ede788b",
            "724239f67fe64995996e52c744e12fb5",
            "391d737493d14e5a8ac9696a303d9ca6",
            "63236fdb7f934e4ebbc918da60265cd4",
            "75fceed9a16b4aaa812d171acbceb3b9",
            "40482d2647104dcc8bf5b5cf37acb2bf",
            "992d2996ebe0432fb3449dd540b32c1e",
            "7ceae08e1a754b9ea03c713957aa2875",
            "cbcc9a9b00bc41a1847cf03b01d7ff41",
            "81cd1c01ed8a44118141e4b8df6fb53a",
            "7de6403b91a4488abbb9235de46db08d"
          ]
        },
        "id": "e4895d59",
        "outputId": "da9afd4d-89bf-413f-a75a-451e6c9052c4"
      },
      "source": [
        "# path: /content/iraqi_marshes_captioner.py\n",
        "\"\"\"\n",
        "Iraqi Marshes Captioner — Structured, clean, domain-scored captions for LoRA training.\n",
        "\n",
        "Pipeline\n",
        "- Mount Drive → scan images → BLIP-large multi-sample → domain scoring → structured caption:\n",
        "  [Scene Phrase] — [Setting] — [Lighting/Style] (+ optional trigger token)\n",
        "- Writes sidecar .txt next to each image and a CSV summary.\n",
        "\n",
        "NOTE\n",
        "- If you ever set `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'` earlier, restart the runtime so BLIP can use the GPU; otherwise it will run on CPU.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2 # Keep cv2 import for image loading, even if not used for face detection\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "from typing import Iterable, Optional, Tuple, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageOps\n",
        "import yaml # Import yaml\n",
        "\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "try:  # Colab only; harmless elsewhere\n",
        "    from google.colab import drive  # type: ignore\n",
        "    _IN_COLAB = True\n",
        "except Exception:  # pragma: no cover\n",
        "    _IN_COLAB = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ---------------------------\n",
        "# Config (edit these) - NOW LOADED FROM YAML\n",
        "# ---------------------------\n",
        "CONFIG_FILE_PATH = \"/content/config.yaml\" # Define config file path\n",
        "\n",
        "# Load configuration from YAML file\n",
        "try:\n",
        "    with open(CONFIG_FILE_PATH, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"[FATAL] Configuration file not found: {CONFIG_FILE_PATH}\")\n",
        "    exit() # Exit if config file is not found\n",
        "\n",
        "# Replace hardcoded configuration variables with values from the config dictionary\n",
        "IMAGE_FOLDER = config.get(\"IMAGE_FOLDER\")\n",
        "OUTPUT_CSV = config.get(\"OUTPUT_CSV\")\n",
        "TRIGGER_TOKEN = config.get(\"TRIGGER_TOKEN\")\n",
        "N_CANDIDATES = config.get(\"N_CANDIDATES\")\n",
        "SKIP_IF_TXT_EXISTS = config.get(\"SKIP_IF_TXT_EXISTS\")\n",
        "BATCH_SIZE = config.get(\"BATCH_SIZE\")\n",
        "DOMAIN_KEYWORDS: List[str] = config.get(\"DOMAIN_KEYWORDS\", [])\n",
        "# Update BANNED_TERMS based on user feedback\n",
        "BANNED_TERMS: List[str] = config.get(\"BANNED_TERMS\", []) + [\"beach\", \"desert\", \"rock\", \"brown bear\", \"elephant\"]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Mount Drive\n",
        "# ---------------------------\n",
        "if _IN_COLAB:\n",
        "    print(\"\\n[INFO] Mounting Google Drive…\")\n",
        "    # Use force_remount=True to handle potential previous failed mounts\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"[INFO] Drive mounted.\")\n",
        "print(f\"[CONFIG] IMAGE_FOLDER = {IMAGE_FOLDER}\")\n",
        "print(f\"[CONFIG] OUTPUT_CSV   = {OUTPUT_CSV}\")\n",
        "print(f\"[CONFIG] BATCH_SIZE   = {BATCH_SIZE}\")\n",
        "\n",
        "\n",
        "# Ensure Google Drive data directory exists (important for os.listdir)\n",
        "# This assumes the parent directories already exist from the Drive mount.\n",
        "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) BLIP captioner\n",
        "# ---------------------------\n",
        "print(\"\\n[INFO] Loading BLIP (Salesforce/blip-image-captioning-large)…\")\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/blip-image-captioning-large\"\n",
        ")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if DEVICE == \"cuda\":\n",
        "    blip_model = blip_model.to(DEVICE)\n",
        "blip_model.eval()\n",
        "print(\"[OK] BLIP ready on\", DEVICE)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) & 3) Removed DeepFace and YuNet\n",
        "# ---------------------------\n",
        "\n",
        "def _pil_load_exif_fixed(path: str) -> Image.Image:\n",
        "    im = Image.open(path)\n",
        "    im = ImageOps.exif_transpose(im)  # auto-rotate based on EXIF\n",
        "    return im.convert(\"RGB\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Text cleaning & replacements\n",
        "# ---------------------------\n",
        "def replace_domain_terms(text: str) -> str:\n",
        "    text = re.sub(r\"\\b(small boat|wooden boat|boat|boats)\\b\", \"mashoof boat\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\b(cow|cows|bull|bulls|buffalo|buffaloes)\\b\", \"水 buffalo\".replace(\"水\", \"water\"), text, flags=re.IGNORECASE)  # keep simple mapping\n",
        "    return text\n",
        "\n",
        "NOISE_PREFIXES = [r\"^utter\\b\", r\"^upon this\\b\", r\"^there is\\b\", r\"^there are\\b\", r\"^##+\\w*\"]\n",
        "\n",
        "def clean_noise(text: str) -> str:\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"#+[A-Za-z0-9_]+\", \"\", t)\n",
        "    t = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", t)\n",
        "    for pat in NOISE_PREFIXES:\n",
        "        t = re.sub(pat, \"\", t, flags=re.IGNORECASE).strip()\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip(\" ,.;:-\")\n",
        "    return t\n",
        "\n",
        "def sentence_case(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return s\n",
        "    return s[0].upper() + s[1:]\n",
        "\n",
        "def finalize_sentence(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return s\n",
        "    if s[-1] not in \".!?\":\n",
        "        s += \".\"\n",
        "    return s\n",
        "\n",
        "# ---------------------------\n",
        "# Post-processing (style & domain polish)\n",
        "# ---------------------------\n",
        "def post_process_caption(text: str) -> str:\n",
        "    \"\"\"Light, safe edits after the structured caption.\"\"\"\n",
        "    import re\n",
        "    t = text\n",
        "\n",
        "    # typos / small fixes\n",
        "    t = re.sub(r\"\\bripplers\\b\", \"ripples\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\bfoto\\b\", \"photo\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # vegetation phrasing → reeds (marsh-accurate)\n",
        "    t = re.sub(r\"\\bfield of tall grass\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\bfield of reeds\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\btall grass\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # starters / subject normalization\n",
        "    t = re.sub(r\"^\\s*this is\\s+\", \"\", t, flags=re.IGNORECASE)         # drop \"This is\"\n",
        "    t = re.sub(r\"^\\s*guy\\b\", \"man\", t, flags=re.IGNORECASE) # Guy → man\n",
        "    t = re.sub(r\"^\\s*gentleman\\b\", \"man\", t, flags=re.IGNORECASE)   # gentleman → man\n",
        "    t = re.sub(r\"^\\s*female\\b\", \"woman\", t, flags=re.IGNORECASE)    # Female → woman\n",
        "\n",
        "    # wording improvements\n",
        "    t = re.sub(r\"\\barabic man\\b\", \"Arab man\", t, flags=re.IGNORECASE) # language→ethnicity\n",
        "    t = re.sub(r\"\\bbarn\\b\", \"hut\", t, flags=re.IGNORECASE)            # better for marsh context\n",
        "    t = re.sub(r\"\\bdesert\\b\", \"muddy banks\", t, flags=re.IGNORECASE) # Correct \"desert\" to \"muddy banks\"\n",
        "    t = re.sub(r\"\\bbeach\\b\", \"water's edge\", t, flags=re.IGNORECASE)  # Correct \"beach\"\n",
        "\n",
        "    # Replace \"brown bear\" and \"elephant\" with \"A water buffalo\"\n",
        "    t = re.sub(r\"\\bbrown bear\\b\", \"A water buffalo\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\belephant\\b\", \"A water buffalo\", t, flags=re.IGNORECASE)\n",
        "\n",
        "\n",
        "    # headscarf normalization & duplicates\n",
        "    t = re.sub(r\"head\\s*scarf\", \"headscarf\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\b(black\\s+)?(?:scarf\\s+and\\s+headscarf|headscarf\\s+and\\s+scarf)\\b\",\n",
        "               lambda m: f\"{(m.group(1) or '').strip()} headscarf\".strip(),\n",
        "               t, flags=re.IGNORECASE)\n",
        "\n",
        "    # trim filler\n",
        "    t = re.sub(r\"\\s+in the background\\b\", \"\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # Correct grammatical errors and awkward phrasing\n",
        "    t = re.sub(r\"\\bheard of children\\b\", \"group of children\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"^\\s*These are a close up\\s+\", \"A close up\", t, flags=re.IGNORECASE)\n",
        "    # Add a rule to handle the completely garbled caption from example #6\n",
        "    if \"Man in a mashoof boat next to a bamboo tree and a lake\" in t:\n",
        "         t = \"A man in a mashoof boat next to a bamboo tree in the marshes.\"\n",
        "\n",
        "\n",
        "    # normalize dashes, whitespace, punctuation\n",
        "    t = re.sub(r\"\\s*—\\s*\", \" — \", t)  # em-dash spacing\n",
        "    t = re.sub(r\"\\s*-\\s*\", \" — \", t)  # hyphen → em-dash between blocks\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    if t and t[-1] not in \".!?\":\n",
        "        t += \".\"\n",
        "    return t\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) BLIP: multi-candidate and scoring\n",
        "# ---------------------------\n",
        "def blip_batch_candidates(image_paths: List[str], n: int = N_CANDIDATES) -> List[List[str]]:\n",
        "    images = [Image.open(img_path).convert(\"RGB\") for img_path in image_paths]\n",
        "    inputs = processor(images=images, return_tensors=\"pt\")\n",
        "    if DEVICE == \"cuda\":\n",
        "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        # Generate n candidates for each image in the batch\n",
        "        out = blip_model.generate(\n",
        "            **inputs,\n",
        "            max_length=120,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=n,\n",
        "        )\n",
        "    # Decode the outputs and group them by image\n",
        "    texts = processor.batch_decode(out, skip_special_tokens=True)\n",
        "    # Reshape the list of texts to be n candidates per image\n",
        "    candidates_per_image: List[List[str]] = []\n",
        "    for i in range(0, len(texts), n):\n",
        "        image_candidates = texts[i : i + n]\n",
        "        # unique while preserving order\n",
        "        seen = set()\n",
        "        unique = []\n",
        "        for t in image_candidates:\n",
        "            if t not in seen:\n",
        "                unique.append(t)\n",
        "                seen.add(t)\n",
        "        candidates_per_image.append(unique)\n",
        "    return candidates_per_image\n",
        "\n",
        "\n",
        "_noise_pat = re.compile(r\"(#\\w+)|(\\b\\w*(?:ooo|aaa)\\w*\\b)\", re.IGNORECASE)\n",
        "\n",
        "def score_caption(raw: str) -> float:\n",
        "    t = raw.lower()\n",
        "    score = 0.0\n",
        "    for kw in DOMAIN_KEYWORDS:\n",
        "        if kw.lower() in t:\n",
        "            score += 2.0\n",
        "    for bad in BANNED_TERMS:\n",
        "        if bad in t:\n",
        "            score -= 3.0\n",
        "    if _noise_pat.search(t):\n",
        "        score -= 3.0\n",
        "    words = re.findall(r\"\\w+\", t)\n",
        "    if len(words) < 8:\n",
        "        score -= 1.0\n",
        "    if len(words) > 28:\n",
        "        score -= 1.0\n",
        "    return score\n",
        "\n",
        "def pick_best_caption(cands: Iterable[str]) -> str:\n",
        "    cands = list(cands)\n",
        "    if not cands:\n",
        "        return \"\"\n",
        "    cleaned = [replace_domain_terms(clean_noise(c)) for c in cands]\n",
        "    scores = [score_caption(c) for c in cleaned]\n",
        "    best_idx = int(np.argmax(scores))\n",
        "    return cleaned[best_idx]\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Structured caption builder\n",
        "# ---------------------------\n",
        "def build_structured_caption(face_data: Optional[Dict[str, object]], scene_phrase: str) -> str:\n",
        "    scene_phrase = sentence_case(scene_phrase)\n",
        "    settings = [\n",
        "        \"Mesopotamian Marshes\", \"Iraqi marshes\", \"reedy channels of Southern Iraq\",\n",
        "    ]\n",
        "    environments = [\n",
        "        \"tall reeds\", \"narrow waterways\", \"shallow marsh water\", \"muddy banks\",\n",
        "    ]\n",
        "    styles = [\n",
        "        \"natural lighting\", \"soft evening light\", \"overcast light\", \"environmental portrait\", \"traditional lifestyle\",\n",
        "    ]\n",
        "\n",
        "    setting = random.choice(settings)\n",
        "    env = random.choice(environments)\n",
        "    style = random.choice(styles)\n",
        "\n",
        "    # Simplified template\n",
        "    parts = [scene_phrase, f\"{setting}, {env}\", style]\n",
        "\n",
        "    caption = \" — \".join([p for p in parts if p])\n",
        "    caption = finalize_sentence(caption)\n",
        "\n",
        "    if TRIGGER_TOKEN:\n",
        "        caption = f\"{caption} {TRIGGER_TOKEN}\"\n",
        "    return caption\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Per-image pipeline + main\n",
        "# ---------------------------\n",
        "def generate_scene_phrases_batch(image_paths: List[str]) -> List[str]:\n",
        "    all_candidates = blip_batch_candidates(image_paths, n=N_CANDIDATES)\n",
        "    best_captions = [pick_best_caption(cands) for cands in all_candidates]\n",
        "    scene_phrases = []\n",
        "    for best in best_captions:\n",
        "        if not best:\n",
        "            best = \"a scene in the traditional Iraqi marshes\"\n",
        "        best = re.sub(r\"^(with)\\s+\", \"\", best, flags=re.IGNORECASE)\n",
        "        best = finalize_sentence(best)\n",
        "        scene_phrases.append(best[:-1]) # remove trailing period for the template join\n",
        "    return scene_phrases\n",
        "\n",
        "\n",
        "def process_single_image_details(img_path: str) -> Optional[Dict[str, object]]:\n",
        "    try:\n",
        "        # Always process, do not skip if TXT exists, instead read existing caption if it exists\n",
        "        txt_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "        existing_caption = None\n",
        "        if os.path.exists(txt_path):\n",
        "             with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                 existing_caption = f.read().strip()\n",
        "\n",
        "        # No face detection is performed in this version\n",
        "        face = None\n",
        "\n",
        "        return {\n",
        "            \"image\": os.path.basename(img_path),\n",
        "            \"face_data\": face, # Face data is always None\n",
        "            \"skipped\": False, # Always process\n",
        "            \"image_path\": img_path, # Keep path for later use\n",
        "            \"existing_caption\": existing_caption # Store existing caption\n",
        "        }\n",
        "    except Exception as e:  # pragma: no cover\n",
        "        print(f\"[WARN] Error processing details for {os.path.basename(img_path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    print(\"\\n================= START =================\")\n",
        "    # Make sure the image folder exists before trying to list files\n",
        "    if not os.path.isdir(IMAGE_FOLDER):\n",
        "         print(f\"[FATAL] Image folder not found: {IMAGE_FOLDER}\")\n",
        "         print(\"[INFO] Please check your Google Drive path or create the folder.\")\n",
        "         return\n",
        "\n",
        "    try:\n",
        "        files = os.listdir(IMAGE_FOLDER)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[FATAL] Folder not found: {IMAGE_FOLDER}\")\n",
        "        return\n",
        "\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
        "    images = [f for f in files if os.path.splitext(f)[1].lower() in exts]\n",
        "\n",
        "    # Add fallback if no images are found\n",
        "    if not images:\n",
        "        print(\"[FATAL] No images found in the specified folder.\")\n",
        "        print(f\"[INFO] Please ensure that '{IMAGE_FOLDER}' contains image files with extensions: {', '.join(exts)}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    print(f\"[INFO] Found {len(images)} images\\n\")\n",
        "    all_results: List[Dict[str, object]] = []\n",
        "    skipped_count = 0 # Skipped count is not relevant anymore as we always process\n",
        "\n",
        "    # Process details for all images first (which now reads existing captions)\n",
        "    print(\"[INFO] Processing image details (reading existing captions)...\")\n",
        "    detail_results = []\n",
        "    for name in tqdm(images, desc=\"Processing images\"):\n",
        "        path = os.path.join(IMAGE_FOLDER, name)\n",
        "        r = process_single_image_details(path)\n",
        "        if r:\n",
        "            detail_results.append(r)\n",
        "\n",
        "\n",
        "    # Separate images with and without existing captions\n",
        "    images_with_existing_captions = [res for res in detail_results if res.get(\"existing_caption\")]\n",
        "    images_without_existing_captions = [res for res in detail_results if not res.get(\"existing_caption\")]\n",
        "\n",
        "\n",
        "    # Process images without existing captions in batches\n",
        "    if not images_without_existing_captions:\n",
        "        print(\"[INFO] No new images to process for initial captioning.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Processing {len(images_without_existing_captions)} images in batches for initial BLIP captioning...\")\n",
        "        image_paths_to_process = [res[\"image_path\"] for res in images_without_existing_captions]\n",
        "        batched_image_paths = [image_paths_to_process[i:i + BATCH_SIZE] for i in range(0, len(image_paths_to_process), BATCH_SIZE)]\n",
        "\n",
        "        caption_results = []\n",
        "        for batch_paths in tqdm(batched_image_paths, desc=\"Generating BLIP captions\"):\n",
        "            batch_scene_phrases = generate_scene_phrases_batch(batch_paths)\n",
        "            for i, scene_phrase in enumerate(batch_scene_phrases):\n",
        "                original_result = next(res for res in images_without_existing_captions if res[\"image_path\"] == batch_paths[i])\n",
        "                face_data = original_result.get(\"face_data\") # This will be None\n",
        "                final_caption = build_structured_caption(face_data, scene_phrase)\n",
        "                final_caption = post_process_caption(final_caption)\n",
        "\n",
        "                # Save sidecar .txt\n",
        "                txt_path = os.path.splitext(batch_paths[i])[0] + \".txt\"\n",
        "                with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(final_caption)\n",
        "\n",
        "                caption_results.append({\n",
        "                    \"image\": original_result[\"image\"],\n",
        "                    \"final_caption\": final_caption,\n",
        "                    \"face_detected\": False, # Always False now\n",
        "                    \"skipped\": False,\n",
        "                })\n",
        "\n",
        "        all_results.extend(caption_results) # Add processed results to the main list\n",
        "\n",
        "    # Process images with existing captions (apply post-processing)\n",
        "    if not images_with_existing_captions:\n",
        "        print(\"[INFO] No existing captions to update.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Updating {len(images_with_existing_captions)} existing captions with post-processing...\")\n",
        "        updated_caption_results = []\n",
        "        for res in tqdm(images_with_existing_captions, desc=\"Updating existing captions\"):\n",
        "            original_caption = res[\"existing_caption\"]\n",
        "            updated_caption = post_process_caption(original_caption)\n",
        "\n",
        "            # Save updated sidecar .txt\n",
        "            txt_path = os.path.splitext(res[\"image_path\"])[0] + \".txt\"\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(updated_caption)\n",
        "\n",
        "            updated_caption_results.append({\n",
        "                \"image\": res[\"image\"],\n",
        "                \"final_caption\": updated_caption,\n",
        "                \"face_detected\": False, # Always False now\n",
        "                \"skipped\": False,\n",
        "            })\n",
        "        all_results.extend(updated_caption_results) # Add updated results to the main list\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(all_results) if all_results else pd.DataFrame(columns=[\"image\", \"final_caption\", \"face_detected\", \"skipped\"])\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"\\n✅ Processed {len(df)} images\")\n",
        "    print(f\"CSV saved to: {OUTPUT_CSV}\")\n",
        "\n",
        "    if not df.empty:\n",
        "        print(\"\\n=== SAMPLE CAPTIONS ===\")\n",
        "        for _, row in df.head(3).iterrows():\n",
        "            print(f\"\\nImage: {row['image']}\")\n",
        "            print(f\"Final: {row['final_caption']}\")\n",
        "    print(\"\\n================= DONE =================\")\n",
        "\n",
        "if __name__ == \"__main__\":  # pragma: no cover\n",
        "    main()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Mounting Google Drive…\n",
            "Mounted at /content/drive\n",
            "[INFO] Drive mounted.\n",
            "[CONFIG] IMAGE_FOLDER = /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo\n",
            "[CONFIG] OUTPUT_CSV   = /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\n",
            "[CONFIG] BATCH_SIZE   = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Loading BLIP (Salesforce/blip-image-captioning-large)…\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f256f4164737407c8e37db8408b221e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e144a2eb640486aacd885f3f32e9a60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19ded68c66ba46478756b95369e20a4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ccfea73f5ff4a699cdda65599c9c9a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eacd6eee99a04443af488cd942ab7d9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00ff03d3720741ddadc15a705b58bf2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "546d1eeeed9b465abb30d56c5ede788b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] BLIP ready on cuda\n",
            "\n",
            "================= START =================\n",
            "[INFO] Found 50 images\n",
            "\n",
            "[INFO] Processing image details (reading existing captions)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 50/50 [00:06<00:00,  8.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] No new images to process for initial captioning.\n",
            "[INFO] Updating 50 existing captions with post-processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Updating existing captions: 100%|██████████| 50/50 [00:00<00:00, 176.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Processed 50 images\n",
            "CSV saved to: /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\n",
            "\n",
            "=== SAMPLE CAPTIONS ===\n",
            "\n",
            "Image: buffalo8.jpg\n",
            "Final: A water buffalo walking across a dry grass covered field near tall reeds — reedy channels of Southern Iraq, narrow waterways — traditional lifestyle.\n",
            "\n",
            "Image: buffalo32.jpg\n",
            "Final: Partly cloudy sky over a muddy river and an A water buffalo in the wild — Iraqi marshes, shallow marsh water — overcast light.\n",
            "\n",
            "Image: buffalo44.jpg\n",
            "Final: A water buffalo — Shallow body of water with a water buffalo walking in it — Iraqi marshes, shallow marsh water — natural lighting.\n",
            "\n",
            "================= DONE =================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137d37d3"
      },
      "source": [
        "## Test the modified script\n",
        "\n",
        "### Subtask:\n",
        "Run the script to ensure it correctly reads the configuration from the file and executes as expected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b975024f"
      },
      "source": [
        "**Reasoning**:\n",
        "The script has been modified to read configuration from the YAML file. The next step is to execute the script to verify that it runs without errors and uses the settings from the `config.yaml` file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1faa99c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563f62fc-b142-4e7e-f42c-66e599db55ba"
      },
      "source": [
        "# path: /content/iraqi_marshes_captioner.py\n",
        "\"\"\"\n",
        "Iraqi Marshes Captioner — Structured, clean, domain-scored captions for LoRA training.\n",
        "\n",
        "Pipeline\n",
        "- Mount Drive → scan images → BLIP-large multi-sample → domain scoring → structured caption:\n",
        "  [Subject] — [Action/Scene] — [Setting] — [Lighting/Style] (+ optional trigger token)\n",
        "- Optional face attributes via DeepFace (OpenCV backend only; never blocks).\n",
        "- Face detection via OpenCV YuNet (ONNX); picks largest face when present.\n",
        "- Writes sidecar .txt next to each image and a CSV summary.\n",
        "\n",
        "NOTE\n",
        "- If you ever set `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'` earlier, restart the runtime so BLIP can use the GPU; otherwise it will run on CPU.\n",
        "\"\"\"\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "from typing import Iterable, Optional, Tuple, List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageOps\n",
        "import yaml # Import yaml\n",
        "\n",
        "import torch\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "try:  # Colab only; harmless elsewhere\n",
        "    from google.colab import drive  # type: ignore\n",
        "    _IN_COLAB = True\n",
        "except Exception:  # pragma: no cover\n",
        "    _IN_COLAB = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ---------------------------\n",
        "# Config (edit these) - NOW LOADED FROM YAML\n",
        "# ---------------------------\n",
        "CONFIG_FILE_PATH = \"/content/config.yaml\" # Define config file path\n",
        "\n",
        "# Load configuration from YAML file\n",
        "try:\n",
        "    with open(CONFIG_FILE_PATH, 'r') as f:\n",
        "        config = yaml.safe_load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"[FATAL] Configuration file not found: {CONFIG_FILE_PATH}\")\n",
        "    exit() # Exit if config file is not found\n",
        "\n",
        "# Replace hardcoded configuration variables with values from the config dictionary\n",
        "IMAGE_FOLDER = config.get(\"IMAGE_FOLDER\")\n",
        "OUTPUT_CSV = config.get(\"OUTPUT_CSV\")\n",
        "TRIGGER_TOKEN = config.get(\"TRIGGER_TOKEN\")\n",
        "N_CANDIDATES = config.get(\"N_CANDIDATES\")\n",
        "SKIP_IF_TXT_EXISTS = config.get(\"SKIP_IF_TXT_EXISTS\")\n",
        "BATCH_SIZE = config.get(\"BATCH_SIZE\")\n",
        "DOMAIN_KEYWORDS: List[str] = config.get(\"DOMAIN_KEYWORDS\", [])\n",
        "BANNED_TERMS: List[str] = config.get(\"BANNED_TERMS\", [])\n",
        "\n",
        "# Original hardcoded config section commented out\n",
        "# # Keep these paths on Google Drive\n",
        "# IMAGE_FOLDER = \"/content/drive/My Drive/Marshes Datasets/faces\"\n",
        "# OUTPUT_CSV = \"/content/drive/My Drive/Marshes Datasets/faces_captions.csv\"\n",
        "# TRIGGER_TOKEN: Optional[str] = None      # e.g., \"marshesX\"\n",
        "# N_CANDIDATES = 3                         # BLIP samples per image\n",
        "# SKIP_IF_TXT_EXISTS = True                # skip images that already have a .txt caption\n",
        "# BATCH_SIZE = 8                           # Number of images to process in each batch\n",
        "\n",
        "# DOMAIN_KEYWORDS: List[str] = [\n",
        "#     \"mashoof\", \"mashoof boat\", \"reeds\", \"reed\", \"marsh\", \"marshes\",\n",
        "#     \"Mesopotamian Marshes\", \"Iraqi marshes\", \"water buffalo\",\n",
        "# ]\n",
        "# BANNED_TERMS: List[str] = [\n",
        "#     \"skier\", \"ski\", \"snow\", \"snowy\", \"mountain\", \"ocean\", \"beach resort\",\n",
        "# ]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Mount Drive\n",
        "# ---------------------------\n",
        "if _IN_COLAB:\n",
        "    print(\"\\n[INFO] Mounting Google Drive…\")\n",
        "    # Use force_remount=True to handle potential previous failed mounts\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"[INFO] Drive mounted.\")\n",
        "print(f\"[CONFIG] IMAGE_FOLDER = {IMAGE_FOLDER}\")\n",
        "print(f\"[CONFIG] OUTPUT_CSV   = {OUTPUT_CSV}\")\n",
        "print(f\"[CONFIG] BATCH_SIZE   = {BATCH_SIZE}\")\n",
        "\n",
        "\n",
        "# Ensure Google Drive data directory exists (important for os.listdir)\n",
        "# This assumes the parent directories already exist from the Drive mount.\n",
        "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1) BLIP captioner\n",
        "# ---------------------------\n",
        "print(\"\\n[INFO] Loading BLIP (Salesforce/blip-image-captioning-large)…\")\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\n",
        "    \"Salesforce/blip-image-captioning-large\"\n",
        ")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if DEVICE == \"cuda\":\n",
        "    blip_model = blip_model.to(DEVICE)\n",
        "blip_model.eval()\n",
        "print(\"[OK] BLIP ready on\", DEVICE)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) (Optional) DeepFace — don’t fail if not available\n",
        "# ---------------------------\n",
        "USE_DEEPFACE = True\n",
        "try:\n",
        "    from deepface import DeepFace  # type: ignore\n",
        "except Exception as e:  # pragma: no cover\n",
        "    print(f\"[INFO] DeepFace not available (optional): {e}\")\n",
        "    USE_DEEPFACE = False\n",
        "\n",
        "# ---------------------------\n",
        "# 3) YuNet detector (OpenCV FaceDetectorYN)\n",
        "# ---------------------------\n",
        "YUNET_PATH = \"/content/face_detection_yunet_2023mar.onnx\"\n",
        "_FACEDETECTOR_AVAILABLE = hasattr(cv2, \"FaceDetectorYN\")\n",
        "\n",
        "if _FACEDETECTOR_AVAILABLE and not os.path.exists(YUNET_PATH):\n",
        "    try:\n",
        "        import urllib.request\n",
        "        print(\"[INFO] Downloading YuNet model…\")\n",
        "        urllib.request.urlretrieve(\n",
        "            \"https://raw.githubusercontent.com/opencv/opencv_zoo/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx\",\n",
        "            YUNET_PATH,\n",
        "        )\n",
        "        print(\"[OK] YuNet downloaded.\")\n",
        "    except Exception as e:  # pragma: no cover\n",
        "        print(f\"[WARN] Could not download YuNet automatically: {e}\")\n",
        "\n",
        "def _pil_load_exif_fixed(path: str) -> Image.Image:\n",
        "    im = Image.open(path)\n",
        "    im = ImageOps.exif_transpose(im)  # auto-rotate based on EXIF\n",
        "    return im.convert(\"RGB\")\n",
        "\n",
        "def _maybe_upscale(np_rgb: np.ndarray, target_long_side: int = 1400) -> np.ndarray:\n",
        "    h, w = np_rgb.shape[:2]\n",
        "    long_side = max(h, w)\n",
        "    if long_side >= target_long_side:\n",
        "        return np_rgb\n",
        "    scale = target_long_side / float(long_side)\n",
        "    new_w, new_h = int(round(w * scale)), int(round(h * scale))\n",
        "    return cv2.resize(np_rgb, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "def _run_yunet(img_bgr: np.ndarray,\n",
        "               score_threshold: float = 0.3,\n",
        "               nms_threshold: float = 0.3,\n",
        "               top_k: int = 500) -> List[Tuple[int, int, int, int, float]]:\n",
        "    if not (_FACEDETECTOR_AVAILABLE and os.path.exists(YUNET_PATH)):\n",
        "        return []\n",
        "    h, w = img_bgr.shape[:2]\n",
        "    try:\n",
        "        det = cv2.FaceDetectorYN.create(\n",
        "            model=YUNET_PATH,\n",
        "            config=\"\",\n",
        "            input_size=(w, h),\n",
        "            score_threshold=score_threshold,\n",
        "            nms_threshold=nms_threshold,\n",
        "            top_k=top_k,\n",
        "        )\n",
        "        det.setInputSize((w, h))\n",
        "        _, faces = det.detect(img_bgr)\n",
        "        if faces is None or len(faces) == 0:\n",
        "            return []\n",
        "        boxes: List[Tuple[int, int, int, int, float]] = []\n",
        "        for f in faces:\n",
        "            x, y, fw, fh, score = f[:5]\n",
        "            boxes.append((int(x), int(y), int(fw), int(fh), float(score)))\n",
        "        return boxes\n",
        "    except Exception as e:  # pragma: no cover\n",
        "        print(f\"[WARN] YuNet failed: {e}\")\n",
        "        return []\n",
        "\n",
        "def _largest_box(boxes: Iterable[Tuple[int, int, int, int, float]],\n",
        "                  img_w: int,\n",
        "                  img_h: int,\n",
        "                  pad: float = 0.06) -> Optional[Tuple[int, int, int, int]]:\n",
        "    boxes = list(boxes)\n",
        "    if not boxes:\n",
        "        return None\n",
        "    x, y, w, h, _ = max(boxes, key=lambda b: b[2] * b[3])\n",
        "    dx, dy = int(w * pad), int(h * pad)\n",
        "    x0 = max(0, x - dx)\n",
        "    y0 = max(0, y - dy)\n",
        "    x1 = min(img_w, x + w + dx)\n",
        "    y1 = min(img_h, y + h + dy)\n",
        "    return x0, y0, x1, y1\n",
        "\n",
        "def robust_detect_face(image_path: str,\n",
        "                       upscale_long_side: int = 1400) -> Tuple[Optional[np.ndarray], Optional[Tuple[int, int, int, int]], Image.Image]:\n",
        "    pil = _pil_load_exif_fixed(image_path)\n",
        "    rgb = np.array(pil)\n",
        "    rgb = _maybe_upscale(rgb, target_long_side=upscale_long_side)\n",
        "    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
        "    H, W = rgb.shape[:2]\n",
        "    boxes = _run_yunet(bgr, score_threshold=0.3, nms_threshold=0.3, top_k=500)\n",
        "    if not boxes:\n",
        "        return None, None, pil\n",
        "    x0y0x1y1 = _largest_box(boxes, W, H, pad=0.06)\n",
        "    if x0y0x1y1 is None:\n",
        "        return None, None, pil\n",
        "    x0, y0, x1, y1 = x0y0x1y1\n",
        "    face_crop_rgb = rgb[y0:y1, x0:x1].copy()\n",
        "    return face_crop_rgb, (x0, y0, x1, y1), Image.fromarray(rgb)\n",
        "\n",
        "def detect_face_details_optional(image_path: str) -> Optional[Dict[str, object]]:\n",
        "    if not USE_DEEPFACE:\n",
        "        return None\n",
        "    face_rgb, _, _ = robust_detect_face(image_path)\n",
        "    if face_rgb is None:\n",
        "        return None\n",
        "    try:\n",
        "        analysis = DeepFace.analyze(  # type: ignore\n",
        "            img_path=face_rgb,\n",
        "            actions=[\"age\", \"gender\", \"emotion\"],\n",
        "            detector_backend=\"opencv\",  # why: avoid TF/RetinaFace to prevent GPU conflicts\n",
        "            enforce_detection=False,\n",
        "            silent=True,\n",
        "        )\n",
        "        if isinstance(analysis, list):\n",
        "            analysis = analysis[0]\n",
        "        return {\n",
        "            \"age\": analysis.get(\"age\"),\n",
        "            \"gender\": analysis.get(\"dominant_gender\"),\n",
        "            \"emotion\": analysis.get(\"dominant_emotion\"),\n",
        "        }\n",
        "    except Exception as e:  # pragma: no cover\n",
        "        print(f\"[INFO] DeepFace analyze failed (continuing without attrs): {e}\")\n",
        "        return None\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Text cleaning & replacements\n",
        "# ---------------------------\n",
        "def replace_domain_terms(text: str) -> str:\n",
        "    text = re.sub(r\"\\b(small boat|wooden boat|boat|boats)\\b\", \"mashoof boat\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\b(cow|cows|bull|bulls|buffalo|buffaloes)\\b\", \"水 buffalo\".replace(\"水\", \"water\"), text, flags=re.IGNORECASE)  # keep simple mapping\n",
        "    return text\n",
        "\n",
        "NOISE_PREFIXES = [r\"^utter\\b\", r\"^upon this\\b\", r\"^there is\\b\", r\"^there are\\b\", r\"^##+\\w*\"]\n",
        "\n",
        "def clean_noise(text: str) -> str:\n",
        "    t = text.strip()\n",
        "    t = re.sub(r\"#+[A-Za-z0-9_]+\", \"\", t)\n",
        "    t = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", t)\n",
        "    for pat in NOISE_PREFIXES:\n",
        "        t = re.sub(pat, \"\", t, flags=re.IGNORECASE).strip()\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip(\" ,.;:-\")\n",
        "    return t\n",
        "\n",
        "def sentence_case(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return s\n",
        "    return s[0].upper() + s[1:]\n",
        "\n",
        "def finalize_sentence(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return s\n",
        "    if s[-1] not in \".!?\":\n",
        "        s += \".\"\n",
        "    return s\n",
        "\n",
        "# ---------------------------\n",
        "# Post-processing (style & domain polish)\n",
        "# ---------------------------\n",
        "def post_process_caption(text: str) -> str:\n",
        "    \"\"\"Light, safe edits after the structured caption.\"\"\"\n",
        "    import re\n",
        "    t = text\n",
        "\n",
        "    # typos / small fixes\n",
        "    t = re.sub(r\"\\bripplers\\b\", \"ripples\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\bfoto\\b\", \"photo\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # vegetation phrasing → reeds (marsh-accurate)\n",
        "    t = re.sub(r\"\\bfield of tall grass\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\bfield of reeds\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\btall grass\\b\", \"tall reeds\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # starters / subject normalization\n",
        "    t = re.sub(r\"^\\s*this is\\s+\", \"\", t, flags=re.IGNORECASE)         # drop \"This is\"\n",
        "    t = re.sub(r\"^\\s*guy\\s+in\\b\", \"A man in\", t, flags=re.IGNORECASE) # Guy → A man\n",
        "    t = re.sub(r\"^\\s*gentleman\\b\", \"A man\", t, flags=re.IGNORECASE)   # gentleman → A man\n",
        "    t = re.sub(r\"^\\s*female\\b\", \"A woman\", t, flags=re.IGNORECASE)    # Female → A woman\n",
        "\n",
        "    # wording improvements\n",
        "    t = re.sub(r\"\\barabic man\\b\", \"Arab man\", t, flags=re.IGNORECASE) # language→ethnicity\n",
        "    t = re.sub(r\"\\bbarn\\b\", \"hut\", t, flags=re.IGNORECASE)            # better for marsh context\n",
        "    t = re.sub(r\"\\bdesert\\b\", \"muddy banks\", t, flags=re.IGNORECASE) # Correct \"desert\" to \"muddy banks\"\n",
        "    t = re.sub(r\"\\bbeach\\b\", \"water's edge\", t, flags=re.IGNORECASE)  # Correct \"beach\"\n",
        "\n",
        "    # headscarf normalization & duplicates\n",
        "    t = re.sub(r\"head\\s*scarf\", \"headscarf\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"\\b(black\\s+)?(?:scarf\\s+and\\s+headscarf|headscarf\\s+and\\s+scarf)\\b\",\n",
        "               lambda m: f\"{(m.group(1) or '').strip()} headscarf\".strip(),\n",
        "               t, flags=re.IGNORECASE)\n",
        "\n",
        "    # trim filler\n",
        "    t = re.sub(r\"\\s+in the background\\b\", \"\", t, flags=re.IGNORECASE)\n",
        "\n",
        "    # Correct grammatical errors and awkward phrasing\n",
        "    t = re.sub(r\"\\bheard of children\\b\", \"group of children\", t, flags=re.IGNORECASE)\n",
        "    t = re.sub(r\"^\\s*These are a close up\\s+\", \"A close up\", t, flags=re.IGNORECASE)\n",
        "    # Add a rule to handle the completely garbled caption from example #6\n",
        "    if \"Man in a mashoof boat next to a bamboo tree and a lake\" in t:\n",
        "         t = \"A man in a mashoof boat next to a bamboo tree in the marshes.\"\n",
        "\n",
        "\n",
        "    # normalize dashes, whitespace, punctuation\n",
        "    t = re.sub(r\"\\s*—\\s*\", \" — \", t)  # em-dash spacing\n",
        "    t = re.sub(r\"\\s*-\\s*\", \" — \", t)  # hyphen → em-dash between blocks\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    if t and t[-1] not in \".!?\":\n",
        "        t += \".\"\n",
        "    return t\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 5) BLIP: multi-candidate and scoring\n",
        "# ---------------------------\n",
        "def blip_batch_candidates(image_paths: List[str], n: int = N_CANDIDATES) -> List[List[str]]:\n",
        "    images = [Image.open(img_path).convert(\"RGB\") for img_path in image_paths]\n",
        "    inputs = processor(images=images, return_tensors=\"pt\")\n",
        "    if DEVICE == \"cuda\":\n",
        "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        # Generate n candidates for each image in the batch\n",
        "        out = blip_model.generate(\n",
        "            **inputs,\n",
        "            max_length=120,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=n,\n",
        "        )\n",
        "    # Decode the outputs and group them by image\n",
        "    texts = processor.batch_decode(out, skip_special_tokens=True)\n",
        "    # Reshape the list of texts to be n candidates per image\n",
        "    candidates_per_image: List[List[str]] = []\n",
        "    for i in range(0, len(texts), n):\n",
        "        image_candidates = texts[i : i + n]\n",
        "        # unique while preserving order\n",
        "        seen = set()\n",
        "        unique = []\n",
        "        for t in image_candidates:\n",
        "            if t not in seen:\n",
        "                unique.append(t)\n",
        "                seen.add(t)\n",
        "        candidates_per_image.append(unique)\n",
        "    return candidates_per_image\n",
        "\n",
        "\n",
        "_noise_pat = re.compile(r\"(#\\w+)|(\\b\\w*(?:ooo|aaa)\\w*\\b)\", re.IGNORECASE)\n",
        "\n",
        "def score_caption(raw: str) -> float:\n",
        "    t = raw.lower()\n",
        "    score = 0.0\n",
        "    for kw in DOMAIN_KEYWORDS:\n",
        "        if kw.lower() in t:\n",
        "            score += 2.0\n",
        "    for bad in BANNED_TERMS:\n",
        "        if bad in t:\n",
        "            score -= 3.0\n",
        "    if _noise_pat.search(t):\n",
        "        score -= 3.0\n",
        "    words = re.findall(r\"\\w+\", t)\n",
        "    if len(words) < 8:\n",
        "        score -= 1.0\n",
        "    if len(words) > 28:\n",
        "        score -= 1.0\n",
        "    return score\n",
        "\n",
        "def pick_best_caption(cands: Iterable[str]) -> str:\n",
        "    cands = list(cands)\n",
        "    if not cands:\n",
        "        return \"\"\n",
        "    cleaned = [replace_domain_terms(clean_noise(c)) for c in cands]\n",
        "    scores = [score_caption(c) for c in cleaned]\n",
        "    best_idx = int(np.argmax(scores))\n",
        "    return cleaned[best_idx]\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Structured caption builder\n",
        "# ---------------------------\n",
        "def build_structured_caption(face_data: Optional[Dict[str, object]], scene_phrase: str) -> str:\n",
        "    scene_phrase = sentence_case(scene_phrase)\n",
        "    settings = [\n",
        "        \"Mesopotamian Marshes\", \"Iraqi marshes\", \"reedy channels of Southern Iraq\",\n",
        "    ]\n",
        "    environments = [\n",
        "        \"tall reeds\", \"narrow waterways\", \"shallow marsh water\", \"muddy banks\",\n",
        "    ]\n",
        "    styles = [\n",
        "        \"natural lighting\", \"soft evening light\", \"overcast light\", \"environmental portrait\", \"traditional lifestyle\",\n",
        "    ]\n",
        "\n",
        "    subject = None\n",
        "    if face_data:\n",
        "        age = face_data.get(\"age\") if isinstance(face_data, dict) else None\n",
        "        if isinstance(age, (int, float)):\n",
        "            if age < 12:\n",
        "                age_desc = \"young child\"\n",
        "            elif age < 18:\n",
        "                age_desc = \"teenage\"\n",
        "            elif age < 30:\n",
        "                age_desc = \"young\"\n",
        "            elif age < 50:\n",
        "                age_desc = \"middle-aged\"\n",
        "            else:\n",
        "                age_desc = \"elderly\"\n",
        "        else:\n",
        "            age_desc = \"adult\"\n",
        "        g = str(face_data.get(\"gender\", \"\")).lower() if isinstance(face_data, dict) else \"\"\n",
        "        if g == \"man\":\n",
        "            gdesc = random.choice([\"man\", \"fisherman\", \"Marsh Arab\"])\n",
        "        elif g == \"woman\":\n",
        "            gdesc = random.choice([\"woman\", \"local woman\", \"Marsh Arab woman\"])\n",
        "        else:\n",
        "            gdesc = \"person\"\n",
        "        subject = f\"A {age_desc} {gdesc}\"\n",
        "    else: # Check scene phrase for domain keywords if no face is detected\n",
        "        scene_lower = scene_phrase.lower()\n",
        "        for keyword in DOMAIN_KEYWORDS:\n",
        "            if keyword.lower() in scene_lower:\n",
        "                # Prioritize specific keywords\n",
        "                if \"mashoof boat\" in keyword.lower():\n",
        "                    subject = \"A mashoof boat\"\n",
        "                    break\n",
        "                elif \"water buffalo\" in keyword.lower():\n",
        "                     # Handle plural and singular forms\n",
        "                    if \"water buffaloes\" in scene_lower:\n",
        "                        subject = \"Water buffaloes\"\n",
        "                    else:\n",
        "                        subject = \"A water buffalo\"\n",
        "                    break\n",
        "                elif \"reeds\" in keyword.lower() or \"reed\" in keyword.lower():\n",
        "                     # Handle plural and singular forms\n",
        "                    if \"reeds\" in scene_lower:\n",
        "                        subject = \"Reeds\"\n",
        "                    else:\n",
        "                        subject = \"A reed\"\n",
        "                    # Continue searching for more prominent subjects\n",
        "                elif \"marshes\" in keyword.lower() or \"marsh\" in keyword.lower():\n",
        "                    subject = \"The marshes\"\n",
        "                    # Continue searching for more prominent subjects\n",
        "\n",
        "\n",
        "    setting = random.choice(settings)\n",
        "    env = random.choice(environments)\n",
        "    style = random.choice(styles)\n",
        "\n",
        "    parts = []\n",
        "    if subject:\n",
        "        parts.append(subject)\n",
        "    parts.append(scene_phrase)\n",
        "    parts.append(f\"{setting}, {env}\")\n",
        "    parts.append(style)\n",
        "\n",
        "    caption = \" — \".join([p for p in parts if p])\n",
        "    caption = finalize_sentence(caption)\n",
        "\n",
        "    if TRIGGER_TOKEN:\n",
        "        caption = f\"{caption} {TRIGGER_TOKEN}\"\n",
        "    return caption\n",
        "# final = build_structured_caption(face, scene)\n",
        "# final = post_process_caption(final)  # <-- must be here\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Per-image pipeline + main\n",
        "# ---------------------------\n",
        "def generate_scene_phrases_batch(image_paths: List[str]) -> List[str]:\n",
        "    all_candidates = blip_batch_candidates(image_paths, n=N_CANDIDATES)\n",
        "    best_captions = [pick_best_caption(cands) for cands in all_candidates]\n",
        "    scene_phrases = []\n",
        "    for best in best_captions:\n",
        "        if not best:\n",
        "            best = \"a scene in the traditional Iraqi marshes\"\n",
        "        best = re.sub(r\"^(with)\\s+\", \"\", best, flags=re.IGNORECASE)\n",
        "        best = finalize_sentence(best)\n",
        "        scene_phrases.append(best[:-1]) # remove trailing period for the template join\n",
        "    return scene_phrases\n",
        "\n",
        "\n",
        "def process_single_image_details(img_path: str) -> Optional[Dict[str, object]]:\n",
        "    try:\n",
        "        if SKIP_IF_TXT_EXISTS:\n",
        "            txt_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "            if os.path.exists(txt_path):\n",
        "                return {\n",
        "                    \"image\": os.path.basename(img_path),\n",
        "                    \"final_caption\": open(txt_path, \"r\", encoding=\"utf-8\").read().strip(),\n",
        "                    \"face_detected\": None,\n",
        "                    \"skipped\": True,\n",
        "                }\n",
        "        # Only perform face detection here, scene generation is batched\n",
        "        face = detect_face_details_optional(img_path)  # may be None\n",
        "\n",
        "        return {\n",
        "            \"image\": os.path.basename(img_path),\n",
        "            \"face_data\": face, # Store face data to build caption later\n",
        "            \"skipped\": False,\n",
        "            \"image_path\": img_path # Keep path for later use\n",
        "        }\n",
        "    except Exception as e:  # pragma: no cover\n",
        "        print(f\"[WARN] Error processing details for {os.path.basename(img_path)}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    print(\"\\n================= START =================\")\n",
        "    # Make sure the image folder exists before trying to list files\n",
        "    if not os.path.isdir(IMAGE_FOLDER):\n",
        "         print(f\"[FATAL] Image folder not found: {IMAGE_FOLDER}\")\n",
        "         print(\"[INFO] Please check your Google Drive path or create the folder.\")\n",
        "         return\n",
        "\n",
        "    try:\n",
        "        files = os.listdir(IMAGE_FOLDER)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"[FATAL] Folder not found: {IMAGE_FOLDER}\")\n",
        "        return\n",
        "\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
        "    images = [f for f in files if os.path.splitext(f)[1].lower() in exts]\n",
        "\n",
        "    # Add fallback if no images are found\n",
        "    if not images:\n",
        "        print(\"[FATAL] No images found in the specified folder.\")\n",
        "        print(f\"[INFO] Please ensure that '{IMAGE_FOLDER}' contains image files with extensions: {', '.join(exts)}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    print(f\"[INFO] Found {len(images)} images\\n\")\n",
        "    all_results: List[Dict[str, object]] = []\n",
        "    skipped_count = 0\n",
        "\n",
        "    # Process details for all images first (face detection)\n",
        "    print(\"[INFO] Processing image details (face detection)...\")\n",
        "    detail_results = []\n",
        "    for name in tqdm(images, desc=\"Detecting faces\"):\n",
        "        path = os.path.join(IMAGE_FOLDER, name)\n",
        "        r = process_single_image_details(path)\n",
        "        if r:\n",
        "            detail_results.append(r)\n",
        "            if r.get(\"skipped\"):\n",
        "                skipped_count += 1\n",
        "                all_results.append({ # Add skipped images to final results immediately\n",
        "                    \"image\": r[\"image\"],\n",
        "                    \"final_caption\": r[\"final_caption\"],\n",
        "                    \"face_detected\": r[\"face_detected\"],\n",
        "                    \"skipped\": True,\n",
        "                })\n",
        "\n",
        "\n",
        "    # Filter out skipped images for batch processing\n",
        "    images_to_process = [res for res in detail_results if not res.get(\"skipped\")]\n",
        "    image_paths_to_process = [res[\"image_path\"] for res in images_to_process]\n",
        "\n",
        "    if not images_to_process:\n",
        "        print(\"[INFO] No new images to process.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Processing {len(images_to_process)} images in batches for BLIP captioning...\")\n",
        "        # Process BLIP captions in batches\n",
        "        batched_image_paths = [image_paths_to_process[i:i + BATCH_SIZE] for i in range(0, len(image_paths_to_process), BATCH_SIZE)]\n",
        "\n",
        "        caption_results = []\n",
        "        for batch_paths in tqdm(batched_image_paths, desc=\"Generating BLIP captions\"):\n",
        "            batch_scene_phrases = generate_scene_phrases_batch(batch_paths)\n",
        "            for i, scene_phrase in enumerate(batch_scene_phrases):\n",
        "                original_result = next(res for res in images_to_process if res[\"image_path\"] == batch_paths[i])\n",
        "                face_data = original_result.get(\"face_data\")\n",
        "                final_caption = build_structured_caption(face_data, scene_phrase)\n",
        "                final_caption = post_process_caption(final_caption)\n",
        "\n",
        "                # Save sidecar .txt\n",
        "                txt_path = os.path.splitext(batch_paths[i])[0] + \".txt\"\n",
        "                with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(final_caption)\n",
        "\n",
        "                caption_results.append({\n",
        "                    \"image\": original_result[\"image\"],\n",
        "                    \"final_caption\": final_caption,\n",
        "                    \"face_detected\": bool(face_data) if face_data is not None else False,\n",
        "                    \"skipped\": False,\n",
        "                })\n",
        "\n",
        "        all_results.extend(caption_results) # Add processed results to the main list\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(all_results) if all_results else pd.DataFrame(columns=[\"image\", \"final_caption\", \"face_detected\", \"skipped\"])\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"\\n✅ Processed {len(df)} images ({skipped_count} skipped)\")\n",
        "    print(f\"CSV saved to: {OUTPUT_CSV}\")\n",
        "\n",
        "    if not df.empty:\n",
        "        print(\"\\n=== SAMPLE CAPTIONS ===\")\n",
        "        for _, row in df.head(3).iterrows():\n",
        "            print(f\"\\nImage: {row['image']}\")\n",
        "            print(f\"Final: {row['final_caption']}\")\n",
        "    print(\"\\n================= DONE =================\")\n",
        "\n",
        "if __name__ == \"__main__\":  # pragma: no cover\n",
        "    main()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] Mounting Google Drive…\n",
            "Mounted at /content/drive\n",
            "[INFO] Drive mounted.\n",
            "[CONFIG] IMAGE_FOLDER = /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo\n",
            "[CONFIG] OUTPUT_CSV   = /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\n",
            "[CONFIG] BATCH_SIZE   = 8\n",
            "\n",
            "[INFO] Loading BLIP (Salesforce/blip-image-captioning-large)…\n",
            "[OK] BLIP ready on cuda\n",
            "[INFO] DeepFace not available (optional): No module named 'deepface'\n",
            "[INFO] Downloading YuNet model…\n",
            "[OK] YuNet downloaded.\n",
            "\n",
            "================= START =================\n",
            "[INFO] Found 50 images\n",
            "\n",
            "[INFO] Processing image details (face detection)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Detecting faces: 100%|██████████| 50/50 [00:00<00:00, 264.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] No new images to process.\n",
            "\n",
            "✅ Processed 50 images (50 skipped)\n",
            "CSV saved to: /content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\n",
            "\n",
            "=== SAMPLE CAPTIONS ===\n",
            "\n",
            "Image: buffalo8.jpg\n",
            "Final: A water buffalo walking across a dry grass covered field near tall reeds — reedy channels of Southern Iraq, narrow waterways — traditional lifestyle.\n",
            "\n",
            "Image: buffalo32.jpg\n",
            "Final: Partly cloudy sky over a muddy river and an A water buffalo in the wild — Iraqi marshes, shallow marsh water — overcast light.\n",
            "\n",
            "Image: buffalo44.jpg\n",
            "Final: A water buffalo — Shallow body of water with a water buffalo walking in it — Iraqi marshes, shallow marsh water — natural lighting.\n",
            "\n",
            "================= DONE =================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73216239",
        "outputId": "f91e6589-5ef9-4e19-cca0-a240e6f62619"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your output CSV file\n",
        "output_csv_path = \"/content/drive/My Drive/MAID-Gen_Dataset/Activities_Wildlife/buffalo_captions.csv\"\n",
        "\n",
        "try:\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    captions_df = pd.read_csv(output_csv_path)\n",
        "\n",
        "    # Display the 'final_caption' column for the first 20 rows\n",
        "    if not captions_df.empty:\n",
        "        print(\"=== First 20 Image Captions ===\")\n",
        "        for index, row in captions_df.head(30).iterrows():\n",
        "            print(f\"{index + 1}: {row['final_caption']}\")\n",
        "    else:\n",
        "        print(\"The CSV file is empty or could not be read.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{output_csv_path}' was not found.\")\n",
        "except KeyError:\n",
        "    print(f\"Error: The column 'final_caption' was not found in the CSV file. Please check the column name.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== First 20 Image Captions ===\n",
            "1: A water buffalo walking across a dry grass covered field near tall reeds — reedy channels of Southern Iraq, narrow waterways — traditional lifestyle.\n",
            "2: Partly cloudy sky over a muddy river and an A water buffalo in the wild — Iraqi marshes, shallow marsh water — overcast light.\n",
            "3: A water buffalo — Shallow body of water with a water buffalo walking in it — Iraqi marshes, shallow marsh water — natural lighting.\n",
            "4: Of a black bear standing in the middle of a body of water — reedy channels of Southern Iraq, tall reeds — traditional lifestyle.\n",
            "5: A water buffalo — Aulent image of a black water buffalo standing in a river — reedy channels of Southern Iraq, shallow marsh water — environmental portrait.\n",
            "6: The marshes — Standing in water in front of a large marshy area with reedy grass — reedy channels of Southern Iraq, muddy banks — environmental portrait.\n",
            "7: The marshes — Hazy sky above a bear and a duck in a marshy area — reedy channels of Southern Iraq, narrow waterways — natural lighting.\n",
            "8: The marshes — Brown dog walking along a muddy river bank in the middle of a marsh — Mesopotamian Marshes, narrow waterways — soft evening light.\n",
            "9: A water buffalo — Water buffalo standing in mud and water in a field near a body of water — Mesopotamian Marshes, shallow marsh water — traditional lifestyle.\n",
            "10: A water buffalo — A water buffalo standing in a field near a body of water — Mesopotamian Marshes, muddy banks — overcast light.\n",
            "11: A water buffalo — This is a picture of a water buffalo walking across a dirt road — Iraqi marshes, tall reeds — overcast light.\n",
            "12: A water buffalo — Dried grass and rocks in field with water buffalo walking away from camera — Mesopotamian Marshes, muddy banks — traditional lifestyle.\n",
            "13: A water buffalo — Water buffalo walking in the mud with a few birds nearby — Iraqi marshes, shallow marsh water — overcast light.\n",
            "14: A water buffalo — Dried grass and dry brush in a field with a water buffalo standing by it — reedy channels of Southern Iraq, tall reeds — traditional lifestyle.\n",
            "15: A water buffalo — Brown water buffalo with black nose and nose looking for food in dry field — Mesopotamian Marshes, tall reeds — natural lighting.\n",
            "16: A water buffalo — Water buffalo standing in dirt field with two horns sticking out of its mouth — reedy channels of Southern Iraq, muddy banks — soft evening light.\n",
            "17: A water buffalo — Dried up water buffalo with horns standing in the dirt on a sunny day — Mesopotamian Marshes, narrow waterways — traditional lifestyle.\n",
            "18: A water buffalo — Grassy area with water buffalo on it and sky in background — Iraqi marshes, muddy banks — traditional lifestyle.\n",
            "19: A water buffalo — Looking down at the face of a black water buffalo with long horns — Iraqi marshes, muddy banks — environmental portrait.\n",
            "20: A water buffalo — Brown and black water buffalo with horns sticking out in field with grass — reedy channels of Southern Iraq, tall reeds — environmental portrait.\n",
            "21: A water buffalo — Three water buffalo standing in a field with their horns out — Iraqi marshes, shallow marsh water — natural lighting.\n",
            "22: A water buffalo — A close up of a water buffalo with a long horn — Mesopotamian Marshes, muddy banks — overcast light.\n",
            "23: A water buffalo — Some big horns of a black water buffalo that are standing in the grass — Iraqi marshes, muddy banks — soft evening light.\n",
            "24: A water buffalo — A pregnant water buffalo with large horns standing on top of a grass covered field — Iraqi marshes, shallow marsh water — overcast light.\n",
            "25: A water buffalo — A black water buffalo standing in water next to grass and reed — Iraqi marshes, muddy banks — traditional lifestyle.\n",
            "26: A water buffalo — A water buffalo walking through a small body of water — Iraqi marshes, muddy banks — overcast light.\n",
            "27: A water buffalo — A brown water buffalo drinking from a lake with tall reeds — Mesopotamian Marshes, narrow waterways — overcast light.\n",
            "28: A water buffalo — Wetland with a water buffalo in the middle and a dog in the back — Iraqi marshes, narrow waterways — environmental portrait.\n",
            "29: A water buffalo — Reedy area with water buffalo in it and one water buffalo standing in water — reedy channels of Southern Iraq, tall reeds — natural lighting.\n",
            "30: A water buffalo — ripples are seen in the water near a water buffalo in the marsh — reedy channels of Southern Iraq, narrow waterways — natural lighting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef00c0c7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to run the script failed because the file was not found. This is likely due to the script not being saved correctly in the previous step. I need to save the script content to the specified file path before running it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a690e0f3"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Ensure the `IMAGE_FOLDER` path specified in the `config.yaml` file points to a valid directory containing images to allow the script to proceed with caption generation.\n"
      ]
    }
  ]
}